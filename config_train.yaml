study_name: dev
experiment_name: dev
seed: 42

allow_overwrite_trial: true  # whether to allow overwrites in the artifacts/study/experiment/trial/ dir
allow_diff_study: true
allow_diff_experiment: true

# all vars below are saved at the experiment level except for checkpoint_every and verbose_batch_loss (which aren't saved at all)
model_type: clip_vitb16
loss_type: infonce
# split_name: S29-0
split_name: dev

n_epochs: 200
checkpoint_every: 1
batch_size_train: 1024
batch_size_val: 1024

lr_init: 1.0e-5
weight_decay: 0.0  # CLIP paper recommends weight_decay = 0.2
beta1: 0.9  # CLIP paper recommends Beta1 = 0.9
beta2: 0.98  # CLIP paper recommends Beta2 = 0.999 (ResNet) / 0.98 (ViT)
eps: 1.0e-6  # CLIP paper recommends eps = 1.0e-8 (ResNet) / 1.0e-6 (ViT)

lr_sched:
  # # Exponential LR Scheduler
  # type: exp
  # args:
  #   lr_min: 1.0e-6
  # args_sched:
  #   gamma: 0.5
  # # Plateau LR Scheduler
  # type: plat  # may also want to tweak threshold / eps
  # args:
  #   reset_best_val: true  # (true) reset best validation score after LR drop to avoid early plateauing
  #   val_type:       loss  # options: loss / perf
  # args_sched:
  #   factor:   0.61803398875  # golden ratio
  #   patience: 1
  #   cooldown: 1
  #   min_lr:   1.0e-7
  # # Cosine LR Scheduler
  # type: cos
  # args:
  #   dummy: null
  # args_sched:
  #   T_max:   5  # half-period
  #   eta_min: 1.0e-7
  # # Cosine Warm-Restarts LR Scheduler
  # type: coswr
  # args:
  #   dummy: null
  # args_sched:
  #   T_0:     7  # period
  #   eta_min: 1.0e-7
  # # Cosine X Exponential LR Scheduler
  # type: cosXexp
  # args:
  #   gamma:      0.98
  #   period:     10
  #   peak_ratio: 10
  #   lr_nom_min: 5.0e-7
  # Cosine Warm-Restarts X Exponential LR Scheduler
  type: coswrXexp
  args:
    gamma:      0.98
    period:     10
    peak_ratio: 10
    lr_nom_min: 5.0e-7

freeze_text_encoder: false
freeze_image_encoder: false

cached_imgs: null  # options: null / pl / pp
mixed_prec: true  # whether to use mixed precision for training and validation
drop_partial_batch_train: true
verbose_batch_loss: false

text_preps_type_train: mixed
text_preps_type_val: bioclip_sci

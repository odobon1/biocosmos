import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import tqdm
import numpy as np

from utils import paths, read_pickle

import pdb


class ImageDataset(Dataset):
    """
    PyTorch requirements for custom Dataset:
    - Inheritance from torch.utils.data.Dataset
    - Implementations of:
        - __len__(self) --> int
        - __getitem__(self, idx) --> sample
    - Everything else is up to you!
    """

    def __init__(self, index_imgs_class_enc, index_imgs_rfpaths, img_pp, cached_imgs=False):
        
        self.index_imgs_class_enc = index_imgs_class_enc
        self.index_imgs_rfpaths   = index_imgs_rfpaths
        self.img_pp               = img_pp
        self.cached_imgs          = cached_imgs

        self.n_samples = len(self.index_imgs_class_enc)

        if self.cached_imgs:
            # load all images into memory (as preprocessed tensors)
            self.imgs_mem = []
            for rfpath in tqdm(self.index_imgs_rfpaths, desc="Preloading, Preprocessing, Caching Images"):
                img   = Image.open(paths["nymph"] / "images" / rfpath).convert("RGB")
                img_t = self.img_pp(img)
                self.imgs_mem.append(img_t)

    def __len__(self):
        return self.n_samples
    
    # gets called in the background on indices of batch N+1 while GPU (and main process) are busy running img2txt_classify() on batch N
    def __getitem__(self, idx):
        """
        Returns transformed image and class encoding.
        idx --> sample (preprocessed image, class encoding)
        """
        class_enc = self.index_imgs_class_enc[idx]

        if self.cached_imgs:
            img_t = self.imgs_mem[idx]
        else:
            # load + preprocess image
            img   = Image.open(paths["nymph"] / "images" / self.index_imgs_rfpaths[idx]).convert("RGB")
            img_t = self.img_pp(img)
        
        return img_t, class_enc

def collate_fn(batch):
    """
    collate_fn takes list of individual samples from Dataset and merges them into a single batch
    augmentation can be done here methinks
    """
    imgs_b, targ_classes_enc_imgs_b = zip(*batch)

    imgs_b = torch.stack(imgs_b, dim=0)  # --- Tensor(B, C, H, W)
    return imgs_b, list(targ_classes_enc_imgs_b)

def spawn_indexes_imgs(split_type, split_name):
    """

    Args:
    - split_type --- [str] --- "train" / "id_val" / "id_test" / "ood_val" / "ood_test"
    - split_name --- [str] --- Name of the split directory e.g. "A" / "B" / etc.
    """
    data_index      = read_pickle(paths["metadata_o"] / f"data_indexes/{split_name}/{split_type}.pkl")
    rank_keys_nymph = read_pickle(paths["metadata_o"] / "rank_keys/nymph.pkl")

    index_imgs_rfpaths   = data_index["rfpaths"]
    index_imgs_sids      = data_index["sids"]
    index_imgs_class_enc = [rank_keys_nymph["species"][sid] for sid in index_imgs_sids]

    index_txts_sids = sorted(set(index_imgs_sids))  # i.e. "classes"

    return np.array(index_imgs_class_enc), np.array(index_imgs_rfpaths), index_txts_sids

def spawn_indexes_txts(index_txts_sids, text_base_type, text_prep_type):
    """
    Note: This was split apart from the spawn_indexes_imgs() logic for ease of setting up the mixed text-types experiment
    
    Args:
    - index_txts_sids --- [list(str)] --- generated by spawn_indexes_imgs()
    """
    rank_keys_nymph = read_pickle(paths["metadata_o"] / "rank_keys/nymph.pkl")

    texts_base = read_pickle(paths["metadata_o"] / f"base_texts/nymph_{text_base_type}.pkl")

    if text_prep_type == "bioclip":
        texts_prepending = "a photo of "  # BioCLIP-style prepending
    elif text_prep_type == "openai":
        texts_prepending = "a photo of a "  # OpenAI CLIP-style prepending
    elif text_prep_type == "base":
        texts_prepending = ""  # no prepending

    index_txts           = [texts_prepending + texts_base[sid] for sid in index_txts_sids]
    index_txts_class_enc = [rank_keys_nymph["species"][sid] for sid in index_txts_sids]

    return np.array(index_txts), np.array(index_txts_class_enc)

def spawn_dataloader(
        index_imgs_class_enc,
        index_imgs_rfpaths,
        img_pp,
        cached_imgs,
        batch_size,
        shuffle,
        num_workers,
        pin_memory,
        prefetch_factor=2,
    ):
    """

    Args:
    - index_imgs_class_enc --- [list(int)] ----------------------------------- Class encodings corresponding to all images in the set
    - index_imgs_rfpaths ----- [list(int)] ----------------------------------- Relative filepaths to images
    - img_pp ----------------- [torchvision.transforms.transforms.Compose] --- The image preprocessor
    - cached_imgs ------------ [bool] ---------------------------------------- Whether to cache images in memory
    - batch_size ------------- [int] ----------------------------------------- Batch size
    - shuffle ---------------- [bool] ---------------------------------------- Whether to shuffle samples between cycles
    - num_workers ------------ [int] ----------------------------------------- Parallelism
    - pin_memory ------------- [bool] ---------------------------------------- (True) speeds up host --> GPU copies, higher RAM cost
    - prefetch_factor -------- [int] ----------------------------------------- How many batches each worker will load in advance;
                                                                               Higher prefetch_factor increases throughput, higher RAM cost;
                                                                               Only takes effect when num_workers > 0
    """

    dataset = ImageDataset(
        index_imgs_class_enc=index_imgs_class_enc,
        index_imgs_rfpaths=index_imgs_rfpaths,
        img_pp=img_pp,
        cached_imgs=cached_imgs,
    )

    loader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory,
        prefetch_factor=prefetch_factor,
        collate_fn=collate_fn,
        drop_last=False,  # whether to drop that last, partial batch
    )

    return loader
